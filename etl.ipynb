{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Configuration\n",
    "OMDB_API_KEY = \"36dc668c\"\n",
    "MOVIES_CSV = \"movies.csv\"\n",
    "RATINGS_CSV = \"ratings.csv\"\n",
    "CACHE_FILE = \"omdb_cache.json\"\n",
    "OUTPUT_DB = \"movie_data.db\"\n",
    "API_SLEEP = 0.25\n",
    "CACHE_SAVE_INTERVAL = 50\n",
    "\n",
    "\n",
    "# Load CSVs\n",
    "movies = pd.read_csv(r\"C:\\Users\\shash\\OneDrive\\Desktop\\etl\\movies.csv\")\n",
    "ratings = pd.read_csv(r\"C:\\Users\\shash\\OneDrive\\Desktop\\etl\\ratings.csv\")\n",
    "\n",
    "print(\"Movies columns:\", movies.columns.tolist())\n",
    "print(movies.head(3))\n",
    "print(\"Ratings columns:\", ratings.columns.tolist())\n",
    "print(ratings.head(3))\n",
    "\n",
    "# Load or initialize cache(api extraction)\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, 'r', encoding='utf-8') as f:\n",
    "        cache = json.load(f)\n",
    "else:\n",
    "    cache = {}\n",
    "\n",
    "def cache_key(title, year):\n",
    "    k = title.strip().lower()\n",
    "    return f\"{k}_{year}\" if year is not None else k\n",
    "\n",
    "def fetch_omdb(title, year=None, api_key=OMDB_API_KEY):\n",
    "    key = cache_key(title, year)\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "\n",
    "    params = {\"t\": title, \"apikey\": api_key}\n",
    "    if year:\n",
    "        params['y'] = str(year)\n",
    "\n",
    "    try:\n",
    "        r = requests.get('http://www.omdbapi.com/', params=params, timeout=8)\n",
    "        data = r.json()\n",
    "\n",
    "        if data.get('Response') == 'False' and year:\n",
    "            params.pop('y', None)\n",
    "            r = requests.get('http://www.omdbapi.com/', params=params, timeout=8)\n",
    "            data = r.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        data = {\"Response\": \"False\", \"Error\": str(e)}\n",
    "\n",
    "    cache[key] = data\n",
    "\n",
    "    if len(cache) % CACHE_SAVE_INTERVAL == 0:\n",
    "        with open(CACHE_FILE, 'w', encoding='utf-8') as f:\n",
    "            json.dump(cache, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    time.sleep(API_SLEEP)\n",
    "    return data\n",
    "\n",
    "# Enrich movies\n",
    "results = []\n",
    "for _, row in tqdm(movies.iterrows(), total=len(movies)):\n",
    "    title = row['title_clean']\n",
    "    year = int(row['year']) if pd.notna(row['year']) else None\n",
    "    data = fetch_omdb(title, year)\n",
    "\n",
    "    results.append({\n",
    "        'movieId': int(row['movieId']),\n",
    "        'title': row['title'],\n",
    "        'title_clean': title,\n",
    "        'year': year,\n",
    "        'director': data.get('Director'),\n",
    "        'plot': data.get('Plot'),\n",
    "        'box_office': data.get('BoxOffice'),\n",
    "        'runtime': data.get('Runtime'),\n",
    "        'released': data.get('Released'),\n",
    "        'language': data.get('Language'),\n",
    "        'actors': data.get('Actors'),\n",
    "        'imdb_id': data.get('imdbID'),\n",
    "        'genre_api': data.get('Genre')\n",
    "    })\n",
    "\n",
    "with open(CACHE_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(cache, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "enriched = pd.DataFrame(results)\n",
    "print('Enriched rows:', enriched.shape)\n",
    "print(enriched.head(3))\n",
    "\n",
    "# Transformation and Merging\n",
    "def parse_runtime(rt):\n",
    "    if pd.isna(rt):\n",
    "        return None\n",
    "    m = re.search(r\"(\\d+)\", str(rt))\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "movies_enriched = movies.merge(enriched.drop(columns=['title']), on='movieId', how='left')\n",
    "movies_enriched['genres_final'] = movies_enriched['genre_api'].fillna(movies_enriched['genres'])\n",
    "movies_enriched['runtime_mins'] = movies_enriched['runtime'].apply(parse_runtime)\n",
    "\n",
    "movies_table = movies_enriched[[\n",
    "    'movieId', 'title', 'title_clean', 'year', 'director', 'plot', 'box_office',\n",
    "    'runtime', 'runtime_mins', 'released', 'language', 'actors', 'imdb_id', 'genres_final'\n",
    "]].rename(columns={'genres_final': 'genres'})\n",
    "\n",
    "ratings_table = ratings[['userId', 'movieId', 'rating', 'timestamp', 'timestamp_converted']].copy()\n",
    "\n",
    "print('Movies table shape:', movies_table.shape)\n",
    "print('Ratings table shape:', ratings_table.shape)\n",
    "\n",
    "# Load to SQLite\n",
    "engine = create_engine(f\"sqlite:///{OUTPUT_DB}\")\n",
    "\n",
    "movies_table.to_sql('movies', con=engine, if_exists='replace', index=False)\n",
    "ratings_table.to_sql('ratings', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "print('Data loaded successfully into', OUTPUT_DB)\n",
    "\n",
    "# Validate the SQLite Database\n",
    "with engine.connect() as conn:\n",
    "    print('Movies count:', conn.execute(text('SELECT COUNT(*) FROM movies')).scalar())\n",
    "    print('Ratings count:', conn.execute(text('SELECT COUNT(*) FROM ratings')).scalar())\n",
    "    display(pd.read_sql('SELECT * FROM movies LIMIT 5', conn))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
